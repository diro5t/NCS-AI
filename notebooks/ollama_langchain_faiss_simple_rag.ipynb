{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of SAP, the term \"Joule\" refers to a unit of energy. This measure of energy is used in various applications within SAP, such as measuring power consumption or power savings. In fact, it's one of the key units used by SAP for power management and optimization.\n"
     ]
    }
   ],
   "source": [
    "# rag-less chain\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# model\n",
    "llm = Ollama(model=\"qwen2:0.5b\")\n",
    "output = StrOutputParser()\n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an eloquent AI assistant\",\n",
    "        ),\n",
    "        (\"human\", \"{user_prompt}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# simple chain\n",
    "chain = prompt | llm | output\n",
    "\n",
    "# run it\n",
    "response = chain.invoke({\"user_prompt\": \"what is the role of joule at sap?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAP's generative AI copilot Joule, which quickly sorts and contextualizes data from multiple systems to advance automation and improve decision-making, is expanding throughout the company's solution portfolio. It is now embedded into SAP S/4HANA Cloud solutions and others including SAP Build and SAP Integration Suite. Further expansion by year-end will include SAP Ariba and SAP Analytics Cloud solutions.\n",
      "The role of Joule at SAP is that it serves as an AI assistant for the RISE with SAP solution implementations, which translates enterprise business requirements into tangible outcomes. It also provides relevant and precise answers to implementation-related questions through the use of NVIDIA's state-of-the-art AI models sifted through SAP consulting assets to provide highly customized analytics applications in SAP Analytics Cloud.\n",
      "Furthermore, Joule is being integrated with Microsoft Copilot to surface even richer insights, making it easier to build generative AI use cases for SAP applications. It has also been upgraded by further expanding its scope by integrating it with Microsoft 365.\n"
     ]
    }
   ],
   "source": [
    "# rag chain\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "# model\n",
    "llm = Ollama(model=\"qwen2:0.5b\")\n",
    "\n",
    "# context document(s)\n",
    "loader = TextLoader(\"../data/sapphire.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "# embedding model\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# embed context document(s) in vector store\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "vector_store = FAISS.from_documents(split_documents, embeddings)\n",
    "\n",
    "# context-augmented prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "            Answer the following question only based on the given context\n",
    "                                                    \n",
    "            <context>\n",
    "            {context}\n",
    "            </context>\n",
    "                                                    \n",
    "            Question: {input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# context retrieval from vector store\n",
    "docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retriever = vector_store.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, docs_chain)\n",
    "\n",
    "# run it\n",
    "response = retrieval_chain.invoke({\"input\": \"what is the role of joule at sap?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
